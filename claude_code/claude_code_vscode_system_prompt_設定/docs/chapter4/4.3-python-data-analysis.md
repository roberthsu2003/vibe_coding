# 4.3 Python 資料分析

## 📋 完整 CLAUDE.md 範例

```markdown
# 專案名稱: Python 資料分析專案

## 🎯 專案概觀
使用 Python 進行資料分析、視覺化和機器學習的專案。

## ⚙️ 技術棧
- **程式語言**: Python 3.11+
- **資料處理**: pandas 2.x, numpy 1.x
- **視覺化**: matplotlib, seaborn, plotly
- **機器學習**: scikit-learn, XGBoost
- **深度學習**: TensorFlow / PyTorch (選用)
- **Notebook**: Jupyter Lab
- **套件管理**: Poetry

## 📏 編碼規範

### Python 風格
- 遵循 PEP 8 風格指南
- 使用 **4 空格縮排** (Python 標準)
- 最大行寬 **88 字元** (Black formatter)
- 使用 **type hints** 標註型別

### 命名慣例
- 變數/函數: `snake_case`
- 類別: `PascalCase`
- 常數: `UPPER_SNAKE_CASE`
- 私有成員: `_leading_underscore`
- 模組: `lowercase`

### Type Hints
\`\`\`python
from typing import List, Dict, Optional, Union
import pandas as pd
import numpy as np

def process_dataframe(
    df: pd.DataFrame,
    columns: List[str],
    threshold: float = 0.5
) -> pd.DataFrame:
    """處理 DataFrame"""
    # 實作
    pass

def calculate_metrics(
    y_true: np.ndarray,
    y_pred: np.ndarray
) -> Dict[str, float]:
    """計算評估指標"""
    return {
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred)
    }
\`\`\`

## 🏗️ 專案結構
\`\`\`
project/
├── data/
│   ├── raw/            # 原始資料
│   ├── processed/      # 處理後資料
│   └── external/       # 外部資料
├── notebooks/          # Jupyter notebooks
├── src/
│   ├── data/          # 資料載入和處理
│   ├── features/      # 特徵工程
│   ├── models/        # 模型定義
│   ├── visualization/ # 視覺化
│   └── utils/         # 工具函數
├── tests/             # 測試
├── outputs/           # 輸出結果
│   ├── figures/       # 圖表
│   └── models/        # 訓練好的模型
└── pyproject.toml     # Poetry 設定
\`\`\`

## 📊 資料處理規範

### Pandas 最佳實踐
- 使用向量化操作,避免迴圈
- 鏈式操作使用括號換行
- 使用 method chaining 提高可讀性
- 明確處理缺失值

#### 資料處理範例
\`\`\`python
import pandas as pd
import numpy as np

# ✅ 正確: 清晰的資料處理流程
def clean_customer_data(df: pd.DataFrame) -> pd.DataFrame:
    """清理客戶資料"""
    return (
        df
        .drop_duplicates(subset=['customer_id'])
        .fillna({
            'age': df['age'].median(),
            'income': df['income'].mean()
        })
        .assign(
            age_group=lambda x: pd.cut(
                x['age'],
                bins=[0, 18, 35, 50, 100],
                labels=['未成年', '青年', '中年', '老年']
            )
        )
        .query('age >= 18')
        .reset_index(drop=True)
    )

# ❌ 錯誤: 使用迴圈處理 DataFrame
for idx, row in df.iterrows():
    df.loc[idx, 'new_col'] = row['col1'] * 2
\`\`\`

### 資料視覺化規範
- 所有圖表包含標題和軸標籤
- 使用適當的顏色配置
- 圖表儲存為高解析度 (dpi >= 300)
- 使用繁體中文字型

#### 視覺化範例
\`\`\`python
import matplotlib.pyplot as plt
import seaborn as sns

# 設定繁體中文字型
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Microsoft JhengHei']
plt.rcParams['axes.unicode_minus'] = False

def plot_distribution(
    data: pd.Series,
    title: str,
    save_path: Optional[str] = None
) -> None:
    """繪製分布圖"""
    fig, ax = plt.subplots(figsize=(10, 6))

    sns.histplot(data, kde=True, ax=ax)
    ax.set_title(title, fontsize=14, fontweight='bold')
    ax.set_xlabel('數值', fontsize=12)
    ax.set_ylabel('頻率', fontsize=12)

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')

    plt.show()
\`\`\`

## 🤖 機器學習規範

### 模型開發流程
1. 資料探索與清理
2. 特徵工程
3. 訓練/測試集分割
4. 模型訓練與驗證
5. 超參數調整
6. 模型評估與比較
7. 結果儲存

### 程式碼範例
\`\`\`python
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
import joblib

def train_classification_model(
    X: pd.DataFrame,
    y: pd.Series,
    model_path: str
) -> None:
    """訓練分類模型"""
    # 1. 分割資料
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # 2. 特徵縮放
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # 3. 訓練模型
    model = RandomForestClassifier(random_state=42)

    # 4. 超參數調整
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 20, 30],
        'min_samples_split': [2, 5, 10]
    }

    grid_search = GridSearchCV(
        model,
        param_grid,
        cv=5,
        scoring='f1_weighted',
        n_jobs=-1
    )

    grid_search.fit(X_train_scaled, y_train)

    # 5. 評估模型
    best_model = grid_search.best_estimator_
    y_pred = best_model.predict(X_test_scaled)

    print("最佳參數:", grid_search.best_params_)
    print("\\n分類報告:")
    print(classification_report(y_test, y_pred))

    # 6. 儲存模型
    joblib.dump({
        'model': best_model,
        'scaler': scaler,
        'feature_names': X.columns.tolist()
    }, model_path)

    print(f"模型已儲存至: {model_path}")
\`\`\`

## 🚫 禁止事項
- ❌ 不使用 `import *`
  ✅ 明確匯入需要的函數/類別

- ❌ 不在迴圈中擴展 DataFrame
  ✅ 先建立 list,最後建立 DataFrame

- ❌ 不忽略警告訊息
  ✅ 適當處理或抑制特定警告

- ❌ 不直接修改原始資料
  ✅ 使用 `.copy()` 建立副本

## 📝 Jupyter Notebook 規範

### Notebook 組織
- 每個 notebook 專注單一主題
- 使用 Markdown cell 說明
- 程式碼 cell 保持簡潔
- 重要結果加入視覺化

### Notebook 結構
\`\`\`markdown
# 標題: 資料分析報告

## 1. 匯入套件
\`\`\`python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
\`\`\`

## 2. 載入資料
\`\`\`python
df = pd.read_csv('data/raw/dataset.csv')
df.head()
\`\`\`

## 3. 資料探索
...

## 4. 資料清理
...

## 5. 特徵工程
...

## 6. 模型訓練
...

## 7. 結果分析
...

## 8. 結論
\`\`\`

## 🧪 測試要求
- 關鍵函數需要單元測試
- 使用 pytest 測試框架
- 測試涵蓋邊界情況
- 資料處理函數測試各種輸入

#### 測試範例
\`\`\`python
import pytest
import pandas as pd
from src.data.preprocessing import clean_customer_data

def test_clean_customer_data():
    # 準備測試資料
    df = pd.DataFrame({
        'customer_id': [1, 2, 2, 3],
        'age': [25, 30, 30, None],
        'income': [50000, 60000, 60000, 70000]
    })

    # 執行函數
    result = clean_customer_data(df)

    # 驗證結果
    assert len(result) == 3  # 移除重複
    assert result['age'].notna().all()  # 填補缺失值
    assert (result['age'] >= 18).all()  # 年齡過濾
\`\`\`

## 📖 文件規範
- 所有函數使用 Google 風格 docstring
- 包含參數說明、回傳值和範例
- 複雜演算法加入參考文獻

#### Docstring 範例
\`\`\`python
def calculate_feature_importance(
    model,
    feature_names: List[str]
) -> pd.DataFrame:
    """計算特徵重要性

    Args:
        model: 訓練好的模型 (須有 feature_importances_ 屬性)
        feature_names: 特徵名稱列表

    Returns:
        pd.DataFrame: 包含特徵名稱和重要性的 DataFrame,
            依重要性降序排列

    Examples:
        >>> model = RandomForestClassifier()
        >>> model.fit(X_train, y_train)
        >>> importance_df = calculate_feature_importance(
        ...     model, X_train.columns.tolist()
        ... )
        >>> print(importance_df.head())
    """
    importance = pd.DataFrame({
        'feature': feature_names,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)

    return importance
\`\`\`

## 🔧 開發工具
- Poetry 管理依賴
- Black 程式碼格式化
- Ruff linting
- mypy 型別檢查
- pytest 測試
```

---

## 🎯 使用此設定

複製內容,儲存為 `CLAUDE.md`,並根據專案調整。

## 導航

- **上一節**: [4.2 Node.js 後端](./4.2-nodejs-backend.md)
- **下一節**: [4.4 全端開發統一規範](./4.4-fullstack.md)
- **返回**: [教材首頁](../../README.md)
