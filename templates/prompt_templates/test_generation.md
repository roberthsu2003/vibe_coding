# Test Generation Prompts

> AI 輔助測試生成的 Prompt 範本集

---

## 單元測試生成

### Prompt 1: 基本單元測試

```
請為以下函式生成完整的單元測試:

測試框架: [Jest / Pytest / JUnit / 其他]

測試需求:
1. Happy path (正常情況)
2. Edge cases (邊界條件)
3. Error handling (錯誤處理)
4. 使用 AAA 模式 (Arrange-Act-Assert)

[貼上函式程式碼]

請提供:
- 完整的測試程式碼
- 測試案例說明
- Mock 策略 (如果需要)
```

---

### Prompt 2: 類別/模組測試

```
請為以下類別生成完整的測試套件:

要求:
1. 測試所有公開方法
2. 測試方法之間的互動
3. 測試狀態改變
4. 測試異常情況

[貼上類別程式碼]

請提供:
- setUp / tearDown (如果需要)
- 每個方法的測試案例
- 測試資料準備
```

---

## 整合測試生成

### Prompt 3: API 端點測試

```
請為以下 API 端點生成整合測試:

測試框架: [Supertest / Pytest + requests / RestAssured]

端點資訊:
- Method: [GET / POST / PUT / DELETE]
- Path: [/api/...]
- 預期行為: [說明]

測試項目:
1. 成功回應 (200, 201, etc.)
2. 錯誤回應 (400, 401, 404, 500, etc.)
3. 請求/回應格式驗證
4. 認證/授權測試

[貼上 API handler 程式碼]

請提供:
- 測試資料庫設定 (test DB setup)
- 完整的測試程式碼
- 測試後的清理 (cleanup)
```

---

### Prompt 4: 資料庫操作測試

```
請為以下資料存取層生成測試:

資料庫: [MongoDB / PostgreSQL / MySQL]
測試工具: [使用 in-memory DB / Docker / Mock]

測試需求:
1. CRUD 操作
2. 查詢邏輯
3. 交易處理
4. 錯誤處理

[貼上 Repository / DAO 程式碼]

請提供:
- 測試資料庫設定
- 測試資料準備 (fixtures / seeds)
- 每個操作的測試案例
- 測試隔離策略
```

---

## E2E 測試生成

### Prompt 5: 使用者流程測試

```
請為以下使用者流程生成 E2E 測試:

測試工具: [Cypress / Playwright / Selenium]

使用者流程:
1. [步驟 1: 例如 訪問首頁]
2. [步驟 2: 例如 點擊登入按鈕]
3. [步驟 3: 例如 填寫表單]
4. [步驟 4: 例如 提交並驗證結果]

請提供:
- 完整的 E2E 測試程式碼
- 測試資料準備
- 選擇器策略 (如何選取 DOM 元素)
- 等待策略 (如何處理非同步)
```

---

## TDD 測試先行

### Prompt 6: TDD - 先寫測試

```
我要用 TDD 方式開發以下功能,請先幫我寫測試:

功能需求:
[詳細描述功能需求]

測試框架: [選擇框架]

請生成:
1. 測試案例列表
2. 完整的測試程式碼
3. 預期這些測試會失敗 (因為功能尚未實作)

執行順序:
1. 先執行測試 (應該全部失敗 - Red)
2. 我會實作功能
3. 再執行測試直到通過 (Green)
4. 然後重構 (Refactor)
```

---

### Prompt 7: TDD - 補完實作

```
以下是我寫好的測試,請幫我實作功能讓測試通過:

[貼上測試程式碼]

實作要求:
1. 實作最簡單的邏輯讓測試通過
2. 不要過度設計
3. 遵循 YAGNI 原則 (You Aren't Gonna Need It)

請提供:
- 功能實作程式碼
- 執行測試的結果
- 如果需要,提供重構建議
```

---

## 測試資料生成

### Prompt 8: 測試資料 (Fixtures)

```
請為以下測試生成測試資料:

資料類型: [User / Product / Order / etc.]

資料需求:
- 數量: [10 / 100 / 1000 筆]
- 格式: [JSON / CSV / SQL]
- 包含: [正常資料 / 邊界資料 / 錯誤資料]

請提供:
- 測試資料檔案
- 載入測試資料的程式碼
- 資料說明 (每筆資料的用途)
```

---

### Prompt 9: Mock 資料生成

```
請為以下外部 API 生成 Mock 資料:

API 規格:
- Endpoint: [API 端點]
- 回應格式: [JSON schema]

Mock 需求:
1. 成功回應的 Mock
2. 失敗回應的 Mock
3. 邊界情況的 Mock

請提供:
- Mock 資料檔案
- 使用 Mock 的測試範例
- Mock server 設定 (如果需要)
```

---

## 特定類型測試

### Prompt 10: React Component 測試

```
請為以下 React 元件生成測試:

測試工具: [React Testing Library / Enzyme]

測試項目:
1. 元件渲染
2. Props 處理
3. 使用者互動 (點擊、輸入)
4. 狀態改變
5. API 呼叫 (需 mock)
6. 條件渲染

[貼上 React 元件]

請提供:
- 完整的測試程式碼
- Mock 設定
- 測試覆蓋率說明
```

---

### Prompt 11: Hooks 測試

```
請為以下 React Hook 生成測試:

測試工具: [@testing-library/react-hooks]

測試項目:
1. Hook 的返回值
2. Hook 的狀態改變
3. Hook 的副作用 (useEffect)
4. Hook 的依賴更新

[貼上 Custom Hook]

請提供:
- 完整的 Hook 測試
- renderHook 的使用範例
```

---

### Prompt 12: Redux/Vuex 測試

```
請為以下 State Management 邏輯生成測試:

框架: [Redux / Vuex / MobX]

測試項目:
1. Actions
2. Reducers / Mutations
3. Selectors / Getters
4. Async actions (thunks / sagas)

[貼上 Store 相關程式碼]
```

---

## 錯誤場景測試

### Prompt 13: 異常處理測試

```
請為以下程式碼生成異常處理測試:

測試場景:
1. 網路錯誤
2. 超時
3. 無效輸入
4. 權限不足
5. 資源不存在

[貼上程式碼]

請提供:
- 每種錯誤場景的測試
- Mock 錯誤的方式
- 驗證錯誤處理是否正確
```

---

## 效能測試

### Prompt 14: 效能基準測試

```
請為以下函式生成效能測試:

測試工具: [Benchmark.js / pytest-benchmark]

測試目標:
1. 測量執行時間
2. 比較不同實作的效能
3. 找出效能瓶頸

[貼上函式程式碼]

請提供:
- 效能測試程式碼
- 測試結果解讀方式
- 效能優化建議
```

---

## 測試覆蓋度分析

### Prompt 15: 提升測試覆蓋率

```
以下是我的測試覆蓋率報告,請幫我生成測試來提升覆蓋率:

當前覆蓋率: [X%]
目標覆蓋率: [Y%]

未涵蓋的程式碼:
[貼上 coverage report 顯示的未涵蓋程式碼]

原始程式碼:
[貼上原始碼]

請提供:
- 新增的測試案例
- 預期可提升的覆蓋率
- 哪些程式碼難以測試 (需要重構)
```

---

## 安全性測試

### Prompt 16: 安全性測試案例

```
請為以下功能生成安全性測試:

功能: [例如: 使用者登入]

安全測試項目:
1. SQL Injection
2. XSS
3. CSRF
4. 認證繞過
5. 權限提升
6. 敏感資料洩漏

[貼上程式碼]

請提供:
- 攻擊場景測試
- 預期的防禦行為
- 安全性檢查清單
```

---

## 測試重構

### Prompt 17: 改善測試品質

```
以下測試可以運作,但品質不佳,請幫我重構:

目前的問題:
- [例如: 測試太長]
- [例如: 測試之間有重複]
- [例如: Mock 太複雜]

[貼上測試程式碼]

重構目標:
1. 提升可讀性
2. 減少重複
3. 簡化 Mock
4. 遵循測試最佳實踐

請提供:
- 重構後的測試
- 改善的地方說明
```

---

## 回歸測試

### Prompt 18: Bug 修復的回歸測試

```
我剛修復了一個 Bug,請幫我生成回歸測試確保不會再發生:

Bug 描述:
[描述 Bug 的情況]

Bug 原因:
[為什麼會發生]

修復方式:
[如何修復]

請生成:
- 重現 Bug 的測試 (在修復前應該失敗)
- 驗證修復的測試 (在修復後應該通過)
- 相關場景的測試 (確保沒有副作用)
```

---

## 測試文檔

### Prompt 19: 生成測試文檔

```
請為以下測試套件生成說明文檔:

[貼上測試程式碼]

文檔內容:
1. 測試套件概覽
2. 每個測試案例的目的
3. 測試資料說明
4. 執行測試的方式
5. 常見問題排解

格式: Markdown
```

---

## 測試最佳實踐檢查

### Prompt 20: 檢查測試品質

```
請審查以下測試,並檢查是否符合最佳實踐:

檢查項目:
1. 測試是否獨立?
2. 測試名稱是否清楚?
3. 是否遵循 AAA 模式?
4. 是否測試實作細節而非行為?
5. Mock 使用是否適當?
6. 測試是否穩定可靠?

[貼上測試程式碼]

請提供:
- 問題清單
- 改進建議
- 重寫範例 (如果需要)
```

---

## 進階測試場景

### Prompt 21: 並發測試

```
請為以下程式碼生成並發/多執行緒測試:

測試場景:
- 多個請求同時執行
- 競態條件 (Race Conditions)
- 死鎖 (Deadlocks)

[貼上程式碼]

請提供:
- 並發測試程式碼
- 如何驗證並發安全性
```

---

### Prompt 22: 快照測試

```
請為以下 UI 元件生成快照測試:

測試工具: [Jest Snapshots / Percy / etc.]

測試項目:
1. 初始渲染快照
2. 不同 Props 的快照
3. 不同狀態的快照

[貼上元件程式碼]
```

---

## 使用技巧

### 如何使用這些 Prompts

1. **選擇適當的測試類型**
   - 單元測試: 測試單一函式/類別
   - 整合測試: 測試模組間互動
   - E2E 測試: 測試完整流程

2. **提供完整的 Context**
   - 貼上被測試的程式碼
   - 說明預期行為
   - 列出已知的邊界情況

3. **迭代改善**
   - 先生成基本測試
   - 執行並觀察結果
   - 根據結果補充更多測試

4. **保持測試品質**
   - 測試應該快速、穩定、獨立
   - 定期審查和重構測試
   - 維持高測試覆蓋率

---

**提示**:
- 好的測試是最好的文檔
- 測試應該比被測試的程式碼更簡單
- 當測試變得複雜時,可能是程式碼需要重構的信號
- 使用 AI 生成測試可以節省時間,但仍需人工審查確保品質
